{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, csv, sys, re, operator\n",
    "from os import path\n",
    "import pandas as pd\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import plot, init_notebook_mode, iplot\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure repository and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userhome = os.path.expanduser('~')\n",
    "txt_file = open(userhome + r\"/DifferentDiffAlgorithms/SZZ/code_document/project_identity.txt\", \"r\")\n",
    "pid = txt_file.read().split('\\n')\n",
    "project = pid[0]\n",
    "bugidentifier = pid[1]\n",
    "proj = project.upper()\n",
    "analyze_dir = userhome + r'/DifferentDiffAlgorithms/SZZ/projects_analyses/' + project + '/'\n",
    "\n",
    "print (\"Project name = %s\" % project)\n",
    "print (\"Project key = %s\" % bugidentifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find valid bug-related lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['myers','histogram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_myers = pd.read_csv(analyze_dir + \"04_affected_versions/02_grouping_affected_non-affected_files/myers_affected_files.csv\")\n",
    "dt_histogram = pd.read_csv(analyze_dir + \"04_affected_versions/02_grouping_affected_non-affected_files/histogram_affected_files.csv\")\n",
    "\n",
    "dt_myers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bugline_myers = dt_myers['myers_#validbugline'].sum()\n",
    "bugline_histogram = dt_histogram['histogram_#validbugline'].sum()\n",
    "validbugline = [[proj,'Myers',bugline_myers],[proj,'Histogram',bugline_histogram]]\n",
    "cols = ['project_name','algorithm','#valid_bug-related_line']\n",
    "with open (analyze_dir + '05_validation/01_valid_buggyline/number_of_valid_bug-related_line.csv','w') as csvfile:\n",
    "    writers = csv.writer(csvfile, delimiter=',')\n",
    "    writers.writerow(cols)\n",
    "    for i in validbugline:\n",
    "        writers.writerow(i)\n",
    "bg = pd.read_csv(analyze_dir + '05_validation/01_valid_buggyline/number_of_valid_bug-related_line.csv')\n",
    "bg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find valid files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycols = ['bug_id','bugfix_commitID','parent_id','filepath','diff_myers_file','blame_myers_file',\n",
    "          'myers_diffnblame_file','myers_#validbugline','myers_affect_version?']\n",
    "myersvalidfiles = dt_myers[mycols]\n",
    "myersvalidfiles.to_csv(analyze_dir + '05_validation/02_validfiles/myers_valid_files.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histcols = ['bug_id','bugfix_commitID','parent_id','filepath','diff_histogram_file','blame_histogram_file','histogram_diffnblame_file','histogram_#validbugline','histogram_affect_version?']\n",
    "histogramvalidfiles = dt_histogram[histcols]\n",
    "histogramvalidfiles.to_csv(analyze_dir + '05_validation/02_validfiles/histogram_valid_files.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validfile = [[proj,'Myers',len(myersvalidfiles)],[proj,'Histogram',len(histogramvalidfiles)]]\n",
    "cols = ['project_name','algorithm','#valid_file']\n",
    "with open (analyze_dir + '05_validation/02_validfiles/number_of_valid_files.csv','w') as csvfile:\n",
    "    writers = csv.writer(csvfile, delimiter=',')\n",
    "    writers.writerow(cols)\n",
    "    for i in validfile:\n",
    "        writers.writerow(i)\n",
    "vf = pd.read_csv(analyze_dir + '05_validation/02_validfiles/number_of_valid_files.csv')\n",
    "vf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the valid bug-fix commit id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Myers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bugfixcid_myers = dt_myers.groupby('bugfix_commitID', as_index=False).agg({\"myers_#validbugline\":\"sum\"})\n",
    "df_bugfixcid_myers.to_csv(analyze_dir + '05_validation/03_validbugfixcommitid/myers_valid_bugfix_commitid.csv')\n",
    "df_bugfixcid_myers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_bugfixcid_hist = dt_histogram.groupby('bugfix_commitID', as_index=False).agg({\"histogram_#validbugline\":\"sum\"})\n",
    "df_bugfixcid_hist.to_csv(analyze_dir + '05_validation/03_validbugfixcommitid/histogram_valid_bugintro_commitid.csv')\n",
    "df_bugfixcid_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validbugfix = [[proj,'Myers',len(df_bugfixcid_myers)],[proj,'Histogram',len(df_bugfixcid_hist)]]\n",
    "cols = ['project_name','algorithm','#valid_bugfix_commitid']\n",
    "with open (analyze_dir + '05_validation/03_validbugfixcommitid/number_of_valid_bugfixcommitid.csv','w') as csvfile:\n",
    "    writers = csv.writer(csvfile, delimiter=',')\n",
    "    writers.writerow(cols)\n",
    "    for i in validbugfix:\n",
    "        writers.writerow(i)\n",
    "vbf = pd.read_csv(analyze_dir + '05_validation/03_validbugfixcommitid/number_of_valid_bugfixcommitid.csv')\n",
    "vbf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find valid bug-introducing change commit id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_dirs = analyze_dir + '03_annotate/02_diff-file_blame-file_comparison/'\n",
    "dirs = []\n",
    "for root, folder, fileList in os.walk(find_dirs):\n",
    "    if folder != []:\n",
    "        dirs.append(folder)\n",
    "dirs.sort()\n",
    "dirs = dirs[0]\n",
    "dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name = ['bug_id','bugintro_commitid','line_number','buggy_code','does_bugline_from_originfile?',\n",
    "               'date_added_in_originfile','earliest_affected_version','version_release_date','bug_class']\n",
    "algorithms = ['myers','histogram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = [dt_myers,dt_histogram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alg in range(0,len(algorithms)):   \n",
    "    result = []\n",
    "    dataset = dt[alg]\n",
    "    for n in range(0, len(dataset)):\n",
    "        sys.stdout.write(\"\\r{} Reading file no: {}\".format((alg+1),(n+1)))\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "        dx = dataset.iloc[n]\n",
    "        file = find_dirs + dirs[alg] + \"/\" + dx[6]\n",
    "\n",
    "        numbug = 1\n",
    "        with open(file,'r') as myfile:\n",
    "            csv_reader = csv.reader(myfile, delimiter=',')\n",
    "            for row in csv_reader:\n",
    "                if row[8] == 'bug-introducing change':\n",
    "                    tmp = [dx[0],dx[1],dx[2],dx[3],dx[6],row[1],row[8],numbug]\n",
    "                    result.append(tmp)\n",
    "\n",
    "    with open(analyze_dir + \"05_validation/04_validbugintrocommitid/\" + algorithms[alg] + \"_valid_bugintro_commitid.csv\",'w') as csvfile:\n",
    "        fields = ['bug_id','bugfix_commitID', 'parent_id','filepath','diffnblame_file','bugintro_commitid',\n",
    "                  'bug_class','#deletion']\n",
    "        writers = csv.writer(csvfile, delimiter=\",\")\n",
    "        writers.writerow(fields)\n",
    "        for item in result:\n",
    "            writers.writerow(item)\n",
    "            \n",
    "print (\"\\nThe process is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bicm = pd.read_csv(analyze_dir + \"05_validation/04_validbugintrocommitid/myers_valid_bugintro_commitid.csv\")\n",
    "bugintromyers = bicm.groupby('bugintro_commitid', as_index=False).agg({\"#deletion\":\"sum\"})\n",
    "bugintromyers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bich = pd.read_csv(analyze_dir + \"05_validation/04_validbugintrocommitid/histogram_valid_bugintro_commitid.csv\")\n",
    "bugintrohist = bich.groupby('bugintro_commitid', as_index=False).agg({\"#deletion\":\"sum\"})\n",
    "bugintrohist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validbugintro = [[proj,'Myers',len(bugintromyers)],[proj,'Histogram',len(bugintrohist)]]\n",
    "cols = ['project_name','algorithm','#valid_bugintro_commitid']\n",
    "with open (analyze_dir + '05_validation/04_validbugintrocommitid/number_of_valid_bugintrocommitid.csv','w') as csvfile:\n",
    "    writers = csv.writer(csvfile, delimiter=',')\n",
    "    writers.writerow(cols)\n",
    "    for i in validbugintro:\n",
    "        writers.writerow(i)\n",
    "vbi = pd.read_csv(analyze_dir + '05_validation/04_validbugintrocommitid/number_of_valid_bugintrocommitid.csv')\n",
    "vbi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge1 = bg.merge(vf, on=['project_name','algorithm'])\n",
    "df_merge2 = df_merge1.merge(vbf, on=['project_name','algorithm'])\n",
    "df_merge3 = df_merge2.merge(vbi, on=['project_name','algorithm'])\n",
    "df_merge3.to_csv(analyze_dir + \"05_validation/05_stats/summary_of_validation.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stat = pd.read_csv(analyze_dir + \"05_validation/05_stats/summary_of_validation.csv\")\n",
    "data_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing number of validated buglines in graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = go.Bar(\n",
    "    x = ['Myers','Histogram'],\n",
    "    y = [data_stat.iloc[0][2],data_stat.iloc[1][2]],\n",
    "    text = [data_stat.iloc[0][2],data_stat.iloc[1][2]],\n",
    "    textposition = 'auto',\n",
    "    marker = dict(\n",
    "        color = 'rgb(150,255,200)',\n",
    "        line = dict(\n",
    "            color='rgb(8,48,107)',\n",
    "            width=1.5),\n",
    "    ),\n",
    "    opacity=0.6\n",
    ")\n",
    "\n",
    "data = [hist]\n",
    "layout = go.Layout(\n",
    "    title = \"Number of validated buglines in \" + proj + \" Project\"\n",
    ")\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, show_link=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing number of validated files, bug-intro and bug-fix commit in graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nummyers = go.Bar(\n",
    "    x = ['#valid_file','#valid_bugfix_commitid','#valid_bugintro_commitid'],\n",
    "    y = [data_stat.iloc[0][3],data_stat.iloc[0][4],data_stat.iloc[0][5]],\n",
    "    text = [data_stat.iloc[0][3],data_stat.iloc[0][4],data_stat.iloc[0][5]],\n",
    "    textposition = 'auto',\n",
    "    name = 'Myers'\n",
    ")\n",
    "\n",
    "\n",
    "numhist = go.Bar(\n",
    "    x = ['#valid_file','#valid_bugfix_commitid','#valid_bugintro_commitid'],\n",
    "    y = [data_stat.iloc[1][3],data_stat.iloc[1][4],data_stat.iloc[1][5]],\n",
    "    text = [data_stat.iloc[1][3],data_stat.iloc[1][4],data_stat.iloc[1][5]],\n",
    "    textposition = 'auto',\n",
    "    name = 'Histogram'\n",
    ")\n",
    "\n",
    "data = [nummyers,numhist]\n",
    "layout = go.Layout(\n",
    "    title = \"Number of valid files, bug-intro commit id and bugfix commit id in \" + proj + \" Project\"\n",
    ")\n",
    "\n",
    "init_notebook_mode(connected=True)\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig, show_link=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
