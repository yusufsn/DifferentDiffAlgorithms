{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, csv, subprocess, sys, re, operator\n",
    "from git import *\n",
    "from subprocess import Popen, PIPE\n",
    "from os import path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configure repository and directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userhome = os.path.expanduser('~')\n",
    "txt_file = open(userhome + r\"/DifferentDiffAlgorithms/SZZ/code_document/project_identity.txt\", \"r\")\n",
    "pid = txt_file.read().split('\\n')\n",
    "project = pid[0]\n",
    "bugidentifier = pid[1]\n",
    "repository = userhome + r'/DifferentDiffAlgorithms/SZZ/datasource/' + project + '/'\n",
    "analyze_dir = userhome + r'/DifferentDiffAlgorithms/SZZ/projects_analyses/' + project + '/'\n",
    "\n",
    "print (\"Project name = %s\" % project)\n",
    "print (\"Project key = %s\" % bugidentifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining function to execute git command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_command(cmd, work_dir):\n",
    "   #Executes a shell command in a subprocess, waiting until it has completed.\n",
    "    pipe = subprocess.Popen(cmd, shell=True, cwd=work_dir, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "    (out, error) = pipe.communicate()\n",
    "    return out, error\n",
    "    pipe.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames = ['bug_id','bugfix_commitID','parent_id','filepath','filename_myers','filename_histogram','#deletions_myers','#deletions_histogram']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffbugs = pd.read_csv(analyze_dir + '02_diff_extraction/03_file_having_deletedlines/buggyfiles_from_both_algorithms.csv')\n",
    "diffbugs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying \"git blame\" for files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = re.compile(r'(?P<commit_id>[\\^]\\w+|\\w+)\\s+(?P<filename>[^\\s]+)\\s+\\((?P<committer>.*?)\\s+(?P<date>\\d{4}-\\d\\d-\\d\\d)\\s+(?P<time>\\d\\d:\\d\\d:\\d\\d).*?(?P<line_number>\\b\\d+\\b)\\)\\s(?P<code>.*)')\n",
    "pattern2 = re.compile(r'(?P<commit_id>[\\^]\\w+|\\w+)\\s+\\((?P<committer>.*?)\\s+(?P<date>\\d{4}-\\d\\d-\\d\\d)\\s+(?P<time>\\d\\d:\\d\\d:\\d\\d).*?(?P<line_number>\\b\\d+\\b)\\)\\s(?P<code>.*)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define header of table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header1 = ['bugintro_commitid', 'filename', 'committer', 'date', 'time', 'line_number', 'code']\n",
    "header2 = ['bugintro_commitid', 'committer', 'date', 'time', 'line_number', 'code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define directory\n",
    "blame_dirs = analyze_dir + '03_annotate/01_annotated_files/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annotating files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errorfile_hist = []\n",
    "errorfile_myers = []\n",
    "df_blame = []\n",
    "for cc in range(0, len(diffbugs)):\n",
    "    sys.stdout.write(\"\\rApplying git blame: %i\" % (cc+1) + \" / %i\" % (len(diffbugs)))\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "    data = diffbugs.iloc[cc]\n",
    "    \n",
    "    parent = data[2]\n",
    "    filepath = data[3]\n",
    "    \n",
    "    bugid = data[0]\n",
    "    fixcid = data[1]\n",
    "    \n",
    "    fn = ((data[3].split('/'))[-1:])[0]\n",
    "    fname = fn + \"_\" + data[1] + \"-\" + data[2][:10] + \"_\" + data[0] \n",
    "    \n",
    "    blametxt = analyze_dir + '03_annotate/01_annotated_files/listof_diff_n_annotated_files/blame_' + fname + '_' + str(cc+1) + '.txt'\n",
    "    \n",
    "    #checkout parentID and applying git blame\n",
    "    checkout = \"git checkout -f \" + parent\n",
    "    blame = \"git blame \" + filepath + \" > \" + blametxt\n",
    "    \n",
    "    execute_command(checkout, repository)\n",
    "    execute_command(blame, repository)\n",
    "    \n",
    "    b = open(blametxt, encoding=\"utf8\", errors='ignore')\n",
    "    c = b.read().split('\\n')\n",
    "\n",
    "    #annotating myers produced files\n",
    "    m_bugnum = data[6]    \n",
    "    if m_bugnum != 0:\n",
    "        mmm = 'blamemyers_' + fname + '_' + str(cc+1) + '.csv'\n",
    "        name = analyze_dir + '03_annotate/01_annotated_files/blame_myers/csv/' + mmm\n",
    "        with open(name, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            try:\n",
    "                try:\n",
    "                    pattern1.match(c[0]).groups()\n",
    "                    writer.writerow(header1)\n",
    "                    for line in c:\n",
    "                        writer.writerow(pattern1.match(line).groups())\n",
    "                except:\n",
    "                    pattern2.match(c[0]).groups()\n",
    "                    writer.writerow(header2)\n",
    "                    for line in c:\n",
    "                        writer.writerow(pattern2.match(line).groups())\n",
    "            except:\n",
    "                if os.stat(blametxt).st_size == 0:\n",
    "                    writer.writerow(header1)\n",
    "                    tmp = [bugid, fixcid, parent, fn, filepath, fname + '_' + str(cc+1), m_bugnum]\n",
    "                    errorfile_myers.append(tmp)\n",
    "                    print (' : ' + fname + '_' + str(cc+1) + ' --> file not found')\n",
    "                pass\n",
    "    else:\n",
    "        mmm = \"-\"\n",
    "            \n",
    "    #annotating histogram produced files\n",
    "    h_bugnum = data[7]\n",
    "    if h_bugnum != 0:\n",
    "        hhh = 'blamehistogram_' + fname + '_' + str(cc+1) + '.csv'\n",
    "        name = analyze_dir + '03_annotate/01_annotated_files/blame_histogram/csv/' + hhh\n",
    "        with open(name, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            try:\n",
    "                try:\n",
    "                    pattern1.match(c[0]).groups()\n",
    "                    writer.writerow(header1)\n",
    "                    for line in c:\n",
    "                        writer.writerow(pattern1.match(line).groups())\n",
    "                except:\n",
    "                    pattern2.match(c[0]).groups()\n",
    "                    writer.writerow(header2)\n",
    "                    for line in c:\n",
    "                        writer.writerow(pattern2.match(line).groups())\n",
    "            except:\n",
    "                if os.stat(blametxt).st_size == 0:\n",
    "                    writer.writerow(header1)\n",
    "                    tmp = [bugid, fixcid, parent, fn, filepath, fname + '_' + str(cc+1), h_bugnum]\n",
    "                    errorfile_hist.append(tmp)\n",
    "                    print (' : ' + fname + '_' + str(cc+1) + ' --> file not found')\n",
    "                pass\n",
    "    else:\n",
    "        hhh = \"-\"\n",
    "\n",
    "    tempo = [data[0],data[1],data[2],data[3],data[4],data[5],mmm,hhh,data[6],data[7]]\n",
    "    df_blame.append(tempo)\n",
    "    \n",
    "#exit from checkout\n",
    "excheck = \"git checkout -f origin\"\n",
    "execute_command(excheck, repository)\n",
    "\n",
    "c = 1\n",
    "for file in glob.iglob(analyze_dir + '03_annotate/01_annotated_files/listof_diff_n_annotated_files/*', recursive=True):\n",
    "    c += 1\n",
    "    try:\n",
    "        os.remove(file)\n",
    "    except FileNotFoundError:\n",
    "        print (\"\\nError: %s\" % (file))\n",
    "        \n",
    "print (\"\\n'git blame' implementation is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save data_frame file into CSV file\n",
    "with open(analyze_dir + '03_annotate/01_annotated_files/listof_diff_n_annotated_files/diff_n_blame_combination_files.csv',\n",
    "          'w') as dfcsv:\n",
    "    header = ['bug_id','bugfix_commitID','parent_id','filepath','diff_myers_file','diff_histogram_file',\n",
    "              'blame_myers_file','blame_histogram_file','#deletions_myers','#deletions_histogram']\n",
    "    writers = csv.writer(dfcsv)\n",
    "    writers.writerow(header)\n",
    "    for file in df_blame:\n",
    "        writers.writerow(file)\n",
    "print (\"The csv file has been created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
